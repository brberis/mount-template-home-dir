{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b9806e",
   "metadata": {},
   "source": [
    "# Computer Vision VOC Dataset Analysis - Updated Path\n",
    "\n",
    "**Dataset Location**: `/home/hccsadmin1/Documents/VOC2012_train_val`\n",
    "\n",
    "This notebook contains the complete computer vision analysis with the correct path for your VOC dataset now located in the Documents folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7536037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. DEFINE PATHS - UPDATED FOR NEW LOCATION\n",
    "# ---------------------------------------------------------------------------\n",
    "# VOC dataset is now located in /home/hccsadmin1/Documents/VOC2012_train_val\n",
    "shared_folder_path = '/home/hccsadmin1/Documents'\n",
    "\n",
    "# Define the path to the Pascal VOC 2012 dataset root\n",
    "voc_root = os.path.join(shared_folder_path, 'VOC2012_train_val')\n",
    "\n",
    "annotations_dir = os.path.join(voc_root, 'Annotations')\n",
    "images_dir = os.path.join(voc_root, 'JPEGImages')\n",
    "\n",
    "print(f\"VOC Dataset Path: {voc_root}\")\n",
    "print(f\"Annotations: {annotations_dir}\")\n",
    "print(f\"Images: {images_dir}\")\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"\\nPath validation:\")\n",
    "print(f\"Dataset root exists: {os.path.exists(voc_root)}\")\n",
    "print(f\"Annotations exists: {os.path.exists(annotations_dir)}\")\n",
    "print(f\"Images exists: {os.path.exists(images_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e72bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 2. PARSE XML ANNOTATIONS AND CREATE A DATAFRAME\n",
    "# ---------------------------------------------------------------------------\n",
    "def parse_voc_annotations(annotations_dir):\n",
    "    \"\"\"Parses all XML files in the Annotations directory.\"\"\"\n",
    "    xml_data = []\n",
    "    \n",
    "    # Loop through every annotation file\n",
    "    for xml_file in os.listdir(annotations_dir):\n",
    "        if not xml_file.endswith('.xml'):\n",
    "            continue\n",
    "        \n",
    "        tree = ET.parse(os.path.join(annotations_dir, xml_file))\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        image_name = root.find('filename').text\n",
    "        \n",
    "        # Find every object in the image\n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text\n",
    "            bbox = obj.find('bndbox')\n",
    "            \n",
    "            # Get bounding box coordinates - FIXED to handle floating-point values\n",
    "            xmin = int(float(bbox.find('xmin').text))\n",
    "            ymin = int(float(bbox.find('ymin').text))\n",
    "            xmax = int(float(bbox.find('xmax').text))\n",
    "            ymax = int(float(bbox.find('ymax').text))\n",
    "            \n",
    "            xml_data.append({\n",
    "                'image_name': image_name,\n",
    "                'label': label,\n",
    "                'xmin': xmin,\n",
    "                'ymin': ymin,\n",
    "                'xmax': xmax,\n",
    "                'ymax': ymax\n",
    "            })\n",
    "    \n",
    "    # Return a pandas DataFrame\n",
    "    return pd.DataFrame(xml_data)\n",
    "\n",
    "print(f\"Parsing annotations from: {annotations_dir}\")\n",
    "try:\n",
    "    # Create the DataFrame\n",
    "    voc_df = parse_voc_annotations(annotations_dir)\n",
    "    print(\"‚úÖ Successfully parsed all annotations.\")\n",
    "    print(f\"Total annotations: {len(voc_df)}\")\n",
    "    print(f\"Unique images: {voc_df['image_name'].nunique()}\")\n",
    "    print(f\"Unique classes: {voc_df['label'].nunique()}\")\n",
    "    print(\"\\nHere are the first 5 entries in the DataFrame:\")\n",
    "    display(voc_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Directory not found at '{annotations_dir}'.\")\n",
    "    print(\"Please check that the dataset path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR: {e}\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12825b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 3. ANALYZE CLASS DISTRIBUTION\n",
    "# ---------------------------------------------------------------------------\n",
    "if 'voc_df' in locals() and not voc_df.empty:\n",
    "    print(\"=== CLASS DISTRIBUTION ===\")\n",
    "    class_counts = voc_df['label'].value_counts()\n",
    "    print(class_counts)\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    class_counts.plot(kind='bar')\n",
    "    plt.title('VOC2012 Object Class Distribution')\n",
    "    plt.xlabel('Object Class')\n",
    "    plt.ylabel('Number of Annotations')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7241f9",
   "metadata": {},
   "source": [
    "# Computer Vision - VOC2012 Dataset Parser\n",
    "\n",
    "This notebook parses Pascal VOC 2012 annotations and visualizes bounding boxes. It handles both direct path access and symbolic link access through SharedContent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b166d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a71873",
   "metadata": {},
   "source": [
    "## 1. Define Paths with Multiple Access Options\n",
    "\n",
    "The notebook tries multiple path configurations to handle different access scenarios:\n",
    "1. Direct access to `/opt/hccs_shared/Share/VOC2012_train_val`\n",
    "2. Access through SharedContent symbolic link\n",
    "3. Local development path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple possible paths for the dataset\n",
    "possible_paths = [\n",
    "    # Direct access (works when running Python directly)\n",
    "    '/opt/hccs_shared/Share/VOC2012_train_val',\n",
    "    \n",
    "    # Through SharedContent symbolic link (for Jupyter notebook access)\n",
    "    '/home/hccsadmin1/SharedContent/VOC2012_train_val',\n",
    "    './SharedContent/VOC2012_train_val',\n",
    "    '../SharedContent/VOC2012_train_val',\n",
    "    \n",
    "    # Local development paths\n",
    "    './VOC2012_train_val',\n",
    "    '../VOC2012_train_val'\n",
    "]\n",
    "\n",
    "# Find the correct path\n",
    "shared_folder_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        shared_folder_path = path\n",
    "        print(f\"‚úÖ Found dataset at: {shared_folder_path}\")\n",
    "        break\n",
    "\n",
    "if shared_folder_path is None:\n",
    "    print(\"‚ùå Dataset not found at any of the expected locations:\")\n",
    "    for path in possible_paths:\n",
    "        print(f\"  - {path}\")\n",
    "    print(\"\\nPlease check your dataset location and update the paths above.\")\n",
    "else:\n",
    "    # Define the standard path to the Pascal VOC 2012 dataset root\n",
    "    voc_root = os.path.join(shared_folder_path, 'VOC2012_train_val')\n",
    "    annotations_dir = os.path.join(voc_root, 'Annotations')\n",
    "    images_dir = os.path.join(voc_root, 'JPEGImages')\n",
    "    \n",
    "    print(f\"üìÅ Annotations directory: {annotations_dir}\")\n",
    "    print(f\"üñºÔ∏è  Images directory: {images_dir}\")\n",
    "    print(f\"üìä Directory exists: {os.path.exists(annotations_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d7cdd",
   "metadata": {},
   "source": [
    "## 2. Parse XML Annotations and Create DataFrame\n",
    "\n",
    "This function parses all XML files in the Annotations directory and extracts bounding box information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_voc_annotations(annotations_dir):\n",
    "    \"\"\"Parses all XML files in the Annotations directory.\"\"\"\n",
    "    if not os.path.exists(annotations_dir):\n",
    "        print(f\"‚ùå Annotations directory not found: {annotations_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    xml_data = []\n",
    "    xml_files = [f for f in os.listdir(annotations_dir) if f.endswith('.xml')]\n",
    "    \n",
    "    print(f\"üìù Found {len(xml_files)} XML annotation files\")\n",
    "    \n",
    "    # Loop through every annotation file\n",
    "    for xml_file in xml_files:\n",
    "        try:\n",
    "            tree = ET.parse(os.path.join(annotations_dir, xml_file))\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            image_name = root.find('filename').text\n",
    "            \n",
    "            # Find every object in the image\n",
    "            for obj in root.findall('object'):\n",
    "                label = obj.find('name').text\n",
    "                bbox = obj.find('bndbox')\n",
    "                \n",
    "                # Get bounding box coordinates (handle float coordinates)\n",
    "                xmin = int(float(bbox.find('xmin').text))\n",
    "                ymin = int(float(bbox.find('ymin').text))\n",
    "                xmax = int(float(bbox.find('xmax').text))\n",
    "                ymax = int(float(bbox.find('ymax').text))\n",
    "                \n",
    "                xml_data.append({\n",
    "                    'image_name': image_name,\n",
    "                    'label': label,\n",
    "                    'xmin': xmin,\n",
    "                    'ymin': ymin,\n",
    "                    'xmax': xmax,\n",
    "                    'ymax': ymax\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error parsing {xml_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ Successfully parsed {len(xml_data)} annotations\")\n",
    "    return pd.DataFrame(xml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse annotations if we found a valid path\n",
    "if shared_folder_path and os.path.exists(annotations_dir):\n",
    "    print(f\"üîç Parsing annotations from: {annotations_dir}\")\n",
    "    voc_df = parse_voc_annotations(annotations_dir)\n",
    "    \n",
    "    if not voc_df.empty:\n",
    "        print(\"‚úÖ Successfully parsed all annotations.\")\n",
    "        print(\"üìä Here are the first 5 entries in the DataFrame:\")\n",
    "        display(voc_df.head())\n",
    "        \n",
    "        print(f\"\\nüìà Dataset Statistics:\")\n",
    "        print(f\"  - Total annotations: {len(voc_df)}\")\n",
    "        print(f\"  - Unique images: {voc_df['image_name'].nunique()}\")\n",
    "        print(f\"  - Unique labels: {voc_df['label'].nunique()}\")\n",
    "        print(f\"  - Labels: {sorted(voc_df['label'].unique())}\")\n",
    "    else:\n",
    "        print(\"‚ùå No annotations were parsed successfully\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed without valid dataset path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6700e13",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Image with Bounding Boxes\n",
    "\n",
    "This function draws bounding boxes on a sample image to visualize the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c26526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(image_name, dataframe, images_dir):\n",
    "    \"\"\"Draws bounding boxes on a given image.\"\"\"\n",
    "    # Get the full path to the image\n",
    "    img_path = os.path.join(images_dir, image_name)\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"‚ùå Image not found: {img_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Open the image\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Get all annotations for this specific image\n",
    "        image_annotations = dataframe[dataframe['image_name'] == image_name]\n",
    "        \n",
    "        print(f\"üñºÔ∏è  Image: {image_name}\")\n",
    "        print(f\"üì¶ Found {len(image_annotations)} bounding boxes\")\n",
    "        \n",
    "        # Draw a rectangle and label for each object\n",
    "        colors = ['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'cyan']\n",
    "        for i, (_, row) in enumerate(image_annotations.iterrows()):\n",
    "            box = [row['xmin'], row['ymin'], row['xmax'], row['ymax']]\n",
    "            color = colors[i % len(colors)]\n",
    "            draw.rectangle(box, outline=color, width=3)\n",
    "            \n",
    "            # Add text label with background\n",
    "            label_text = row['label']\n",
    "            text_bbox = draw.textbbox((row['xmin'], row['ymin']), label_text)\n",
    "            draw.rectangle(text_bbox, fill=color)\n",
    "            draw.text((row['xmin'], row['ymin']), label_text, fill=\"white\")\n",
    "            \n",
    "            print(f\"  - {label_text}: ({row['xmin']}, {row['ymin']}) to ({row['xmax']}, {row['ymax']})\")\n",
    "\n",
    "        print(f\"üé® Displaying image '{image_name}' with bounding boxes:\")\n",
    "        display(img)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error visualizing image {image_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a random image from the dataset\n",
    "if 'voc_df' in locals() and not voc_df.empty and shared_folder_path:\n",
    "    try:\n",
    "        sample_image = voc_df['image_name'].sample(1).iloc[0]\n",
    "        visualize_image(sample_image, voc_df, images_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during visualization: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd04197",
   "metadata": {},
   "source": [
    "## 4. Dataset Analysis\n",
    "\n",
    "Let's analyze the dataset to understand the distribution of object classes and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the dataset\n",
    "if 'voc_df' in locals() and not voc_df.empty:\n",
    "    print(\"üìä Dataset Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Class distribution\n",
    "    class_counts = voc_df['label'].value_counts()\n",
    "    print(f\"\\nüè∑Ô∏è  Object Class Distribution:\")\n",
    "    for label, count in class_counts.head(10).items():\n",
    "        print(f\"  {label}: {count} annotations\")\n",
    "    \n",
    "    # Images with most annotations\n",
    "    image_counts = voc_df['image_name'].value_counts()\n",
    "    print(f\"\\nüñºÔ∏è  Images with Most Annotations:\")\n",
    "    for image, count in image_counts.head(5).items():\n",
    "        print(f\"  {image}: {count} objects\")\n",
    "    \n",
    "    # Bounding box size analysis\n",
    "    voc_df['width'] = voc_df['xmax'] - voc_df['xmin']\n",
    "    voc_df['height'] = voc_df['ymax'] - voc_df['ymin']\n",
    "    voc_df['area'] = voc_df['width'] * voc_df['height']\n",
    "    \n",
    "    print(f\"\\nüìè Bounding Box Statistics:\")\n",
    "    print(f\"  Average width: {voc_df['width'].mean():.1f} pixels\")\n",
    "    print(f\"  Average height: {voc_df['height'].mean():.1f} pixels\")\n",
    "    print(f\"  Average area: {voc_df['area'].mean():.1f} square pixels\")\n",
    "    \n",
    "    display(voc_df[['label', 'width', 'height', 'area']].describe())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6ca51",
   "metadata": {},
   "source": [
    "## 5. Troubleshooting\n",
    "\n",
    "If you're having issues accessing the dataset, try these steps:\n",
    "\n",
    "1. **Check if the symbolic link works:**\n",
    "   ```bash\n",
    "   ls -la ~/SharedContent/\n",
    "   ```\n",
    "\n",
    "2. **Check if you can access the dataset directly:**\n",
    "   ```bash\n",
    "   ls /opt/hccs_shared/Share/VOC2012_train_val/\n",
    "   ```\n",
    "\n",
    "3. **Check Jupyter permissions:**\n",
    "   ```bash\n",
    "   whoami\n",
    "   groups\n",
    "   ```\n",
    "\n",
    "4. **Alternative: Copy dataset to accessible location:**\n",
    "   ```bash\n",
    "   cp -r /opt/hccs_shared/Share/VOC2012_train_val ~/VOC2012_train_val\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
